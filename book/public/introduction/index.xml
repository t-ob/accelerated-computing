<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on Introduction to accelerated computing</title>
    <link>https://accelerated-computing.com/introduction/</link>
    <description>Recent content in Introduction on Introduction to accelerated computing</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Jun 2023 15:40:25 +0100</lastBuildDate><atom:link href="https://accelerated-computing.com/introduction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CUDA concepts</title>
      <link>https://accelerated-computing.com/introduction/cuda-concepts/</link>
      <pubDate>Wed, 07 Jun 2023 15:40:25 +0100</pubDate>
      
      <guid>https://accelerated-computing.com/introduction/cuda-concepts/</guid>
      <description>CUDA concepts By the end of this chapter we will have written a simple program which does the following:
Copies data from the host machine to a GPU. Performs some computation on that data. Copies the result back to the host. Before we can do that, we need to cover some key concepts.
Kernels The CUDA programming model has at its core the concept of a kernel as its basic unit of execution.</description>
    </item>
    
    <item>
      <title>Example: scalar product</title>
      <link>https://accelerated-computing.com/introduction/example-scalar-product/</link>
      <pubDate>Wed, 07 Jun 2023 15:40:25 +0100</pubDate>
      
      <guid>https://accelerated-computing.com/introduction/example-scalar-product/</guid>
      <description>Example: scalar product We&amp;rsquo;ll use the example of computing the scalar product of two floating point vectors. Recall that, for two vectors $x = (x_i)$ and $y = (y_i)$ of some $n$-dimensional vector space, their scalar (or dot) product $x \cdot y$ is the sum of the pairwise products of each vector&amp;rsquo;s components: $$ x \cdot y = \sum_{i=0}^{n - 1} x_i y_i $$
The scalar product is a worthwhile place to start for two reasons:</description>
    </item>
    
    <item>
      <title>Putting it all together</title>
      <link>https://accelerated-computing.com/introduction/putting-it-all-together/</link>
      <pubDate>Wed, 07 Jun 2023 15:40:25 +0100</pubDate>
      
      <guid>https://accelerated-computing.com/introduction/putting-it-all-together/</guid>
      <description>Putting it all together At this point, we&amp;rsquo;ve written the kernels which will do our heavy lifting. We still need to call these from the host. Let&amp;rsquo;s put this all together in a complete program. It does the following:
Declares a block size of 256. Creates two constant vectors of length 1048576 and copies them to the GPU. Allocates additional memory on the GPU to store the output of their pairwise component products.</description>
    </item>
    
    <item>
      <title>Performance</title>
      <link>https://accelerated-computing.com/introduction/performance/</link>
      <pubDate>Wed, 07 Jun 2023 15:40:25 +0100</pubDate>
      
      <guid>https://accelerated-computing.com/introduction/performance/</guid>
      <description>Performance Now that we have our first CUDA program under our belt, we should ask ourselves: was it all worth it? After all, we have jumped through a fair few hoops to accomplish what can be expressed as a one-liner in Python:
def scalar_product(xs, ys): return sum(x * y for x, y in zip(xs, ys)) This is a contrived example, but it illustrates the tradeoffs involved in CUDA programming, namely performance (which we are still yet to measure!</description>
    </item>
    
  </channel>
</rss>
